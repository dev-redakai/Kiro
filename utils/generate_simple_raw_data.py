#!/usr/bin/env python3\n\"\"\"\nSimple Raw Data Generator for Pipeline Testing\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport logging\n\n# Add src to path for imports\nsys.path.insert(0, 'src')\n\nfrom utils.test_data_generator import TestDataGenerator\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\ndef ensure_directories():\n    \"\"\"Ensure required directories exist.\"\"\"\n    directories = [\n        'data/raw',\n        'data/raw/clean',\n        'data/raw/dirty', \n        'data/raw/anomaly',\n        'data/raw/mixed',\n        'data/raw/performance',\n        'data/raw/validation_test'\n    ]\n    \n    for directory in directories:\n        Path(directory).mkdir(parents=True, exist_ok=True)\n        print(f\"✅ Created directory: {directory}\")\n\ndef apply_validation_test_modifications(df, test_type):\n    \"\"\"Apply specific modifications to test validation rules.\"\"\"\n    if test_type == 'null_order_ids':\n        # Make 20% of order IDs null or empty\n        null_indices = np.random.choice(df.index, size=int(len(df) * 0.2), replace=False)\n        for idx in null_indices:\n            df.at[idx, 'order_id'] = np.random.choice([None, '', '   ', 'NULL'])\n    \n    elif test_type == 'duplicate_order_ids':\n        # Create duplicates for 15% of records\n        duplicate_indices = np.random.choice(df.index, size=int(len(df) * 0.15), replace=False)\n        for i in range(0, len(duplicate_indices)-1, 2):\n            if i+1 < len(duplicate_indices):\n                df.at[duplicate_indices[i+1], 'order_id'] = df.at[duplicate_indices[i], 'order_id']\n    \n    elif test_type == 'invalid_categories':\n        # Add invalid categories\n        invalid_categories = ['Home Goods', 'Books', 'Sports', 'Automotive', 'Invalid', '', None]\n        invalid_indices = np.random.choice(df.index, size=int(len(df) * 0.3), replace=False)\n        for idx in invalid_indices:\n            df.at[idx, 'category'] = np.random.choice(invalid_categories)\n    \n    elif test_type == 'invalid_quantities':\n        # Add invalid quantities\n        df['quantity'] = df['quantity'].astype('object')  # Allow mixed types\n        invalid_indices = np.random.choice(df.index, size=int(len(df) * 0.25), replace=False)\n        for idx in invalid_indices:\n            invalid_qty = np.random.choice([0, -1, -10, 15000, 'invalid', '', None, '0', '-5'])\n            df.at[idx, 'quantity'] = invalid_qty\n    \n    elif test_type == 'invalid_emails':\n        # Add invalid email formats\n        invalid_emails = [\n            'invalid-email', 'user@', '@domain.com', 'user.domain.com',\n            'user@domain', 'user name@domain.com', 'user@.com', \n            'user@@domain.com', '', None, 'not-an-email'\n        ]\n        invalid_indices = np.random.choice(df.index, size=int(len(df) * 0.22), replace=False)\n        for idx in invalid_indices:\n            df.at[idx, 'customer_email'] = np.random.choice(invalid_emails)\n    \n    return df\n\ndef main():\n    \"\"\"Generate various raw data samples.\"\"\"\n    print(\"🚀 Starting raw data generation...\")\n    \n    # Ensure directories exist\n    ensure_directories()\n    \n    # Initialize generator\n    generator = TestDataGenerator(seed=42)\n    \n    datasets_to_generate = [\n        # Clean datasets\n        {\n            'name': 'small_clean_sample.csv',\n            'type': 'clean',\n            'size': 1000,\n            'output_dir': 'data/raw/clean',\n            'description': 'Small clean dataset for quick testing'\n        },\n        {\n            'name': 'medium_clean_sample.csv',\n            'type': 'clean',\n            'size': 10000,\n            'output_dir': 'data/raw/clean',\n            'description': 'Medium clean dataset for standard testing'\n        },\n        {\n            'name': 'large_clean_sample.csv',\n            'type': 'clean',\n            'size': 50000,\n            'output_dir': 'data/raw/clean',\n            'description': 'Large clean dataset for performance testing'\n        },\n        \n        # Dirty datasets\n        {\n            'name': 'dirty_sample_30pct.csv',\n            'type': 'dirty',\n            'size': 5000,\n            'dirty_ratio': 0.30,\n            'output_dir': 'data/raw/dirty',\n            'description': 'Dataset with 30% data quality issues'\n        },\n        {\n            'name': 'dirty_sample_50pct.csv',\n            'type': 'dirty',\n            'size': 3000,\n            'dirty_ratio': 0.50,\n            'output_dir': 'data/raw/dirty',\n            'description': 'Dataset with 50% data quality issues'\n        },\n        \n        # Anomaly datasets\n        {\n            'name': 'anomaly_sample_5pct.csv',\n            'type': 'anomaly',\n            'size': 4000,\n            'anomaly_ratio': 0.05,\n            'output_dir': 'data/raw/anomaly',\n            'description': 'Dataset with 5% anomalous transactions'\n        },\n        {\n            'name': 'anomaly_sample_10pct.csv',\n            'type': 'anomaly',\n            'size': 2000,\n            'anomaly_ratio': 0.10,\n            'output_dir': 'data/raw/anomaly',\n            'description': 'Dataset with 10% anomalous transactions'\n        },\n        \n        # Mixed datasets\n        {\n            'name': 'realistic_mixed_sample.csv',\n            'type': 'mixed',\n            'size': 8000,\n            'output_dir': 'data/raw/mixed',\n            'description': 'Realistic mixed dataset (70% clean, 25% dirty, 5% anomaly)'\n        },\n        \n        # Performance datasets\n        {\n            'name': 'performance_100k.csv',\n            'type': 'clean',\n            'size': 100000,\n            'output_dir': 'data/raw/performance',\n            'description': '100K records for performance testing'\n        },\n        \n        # Validation test datasets\n        {\n            'name': 'null_order_ids_test.csv',\n            'type': 'validation_test',\n            'size': 2000,\n            'test_type': 'null_order_ids',\n            'output_dir': 'data/raw/validation_test',\n            'description': 'Dataset to test order_id_not_null validation'\n        },\n        {\n            'name': 'duplicate_order_ids_test.csv',\n            'type': 'validation_test',\n            'size': 2000,\n            'test_type': 'duplicate_order_ids',\n            'output_dir': 'data/raw/validation_test',\n            'description': 'Dataset to test order_id_unique validation'\n        },\n        {\n            'name': 'invalid_categories_test.csv',\n            'type': 'validation_test',\n            'size': 2000,\n            'test_type': 'invalid_categories',\n            'output_dir': 'data/raw/validation_test',\n            'description': 'Dataset to test category_enum validation'\n        },\n        {\n            'name': 'invalid_quantities_test.csv',\n            'type': 'validation_test',\n            'size': 2000,\n            'test_type': 'invalid_quantities',\n            'output_dir': 'data/raw/validation_test',\n            'description': 'Dataset to test quantity validation rules'\n        },\n        {\n            'name': 'invalid_emails_test.csv',\n            'type': 'validation_test',\n            'size': 2000,\n            'test_type': 'invalid_emails',\n            'output_dir': 'data/raw/validation_test',\n            'description': 'Dataset to test email format validation'\n        }\n    ]\n    \n    results = []\n    \n    for dataset_config in datasets_to_generate:\n        try:\n            print(f\"\\n📊 Generating {dataset_config['name']}...\")\n            \n            # Generate dataset based on type\n            if dataset_config['type'] == 'clean':\n                df = generator.generate_clean_sample(dataset_config['size'])\n            elif dataset_config['type'] == 'dirty':\n                df = generator.generate_dirty_sample(\n                    dataset_config['size'], \n                    dirty_ratio=dataset_config.get('dirty_ratio', 0.3)\n                )\n            elif dataset_config['type'] == 'anomaly':\n                df = generator.generate_anomaly_sample(\n                    dataset_config['size'], \n                    anomaly_ratio=dataset_config.get('anomaly_ratio', 0.05)\n                )\n            elif dataset_config['type'] == 'mixed':\n                df = generator.generate_configurable_dataset({\n                    'size': dataset_config['size'],\n                    'type': 'mixed'\n                })\n            elif dataset_config['type'] == 'validation_test':\n                # Generate clean data first, then apply test modifications\n                df = generator.generate_clean_sample(dataset_config['size'])\n                df = apply_validation_test_modifications(df, dataset_config['test_type'])\n            else:\n                raise ValueError(f\"Unknown dataset type: {dataset_config['type']}\")\n            \n            # Save dataset\n            filepath = generator.save_dataset(\n                df, \n                dataset_config['name'], \n                dataset_config['output_dir']\n            )\n            \n            # Calculate file size\n            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)\n            \n            result = {\n                'name': dataset_config['name'],\n                'filepath': filepath,\n                'records': len(df),\n                'file_size_mb': round(file_size_mb, 2),\n                'type': dataset_config['type'],\n                'description': dataset_config['description']\n            }\n            \n            results.append(result)\n            \n            print(f\"   ✅ Generated: {len(df):,} records ({file_size_mb:.1f} MB)\")\n            print(f\"   📁 Saved to: {filepath}\")\n            \n        except Exception as e:\n            print(f\"   ❌ Failed to generate {dataset_config['name']}: {e}\")\n            logger.error(f\"Error generating {dataset_config['name']}: {e}\")\n            results.append({\n                'name': dataset_config['name'],\n                'error': str(e)\n            })\n    \n    # Print summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"📊 RAW DATA GENERATION SUMMARY\")\n    print(\"=\"*80)\n    \n    successful = [r for r in results if 'error' not in r]\n    failed = [r for r in results if 'error' in r]\n    \n    total_records = sum(r.get('records', 0) for r in successful)\n    total_size_mb = sum(r.get('file_size_mb', 0) for r in successful)\n    \n    print(f\"\\n✅ Successful datasets: {len(successful)}\")\n    print(f\"❌ Failed datasets: {len(failed)}\")\n    print(f\"📊 Total records generated: {total_records:,}\")\n    print(f\"💾 Total file size: {total_size_mb:.1f} MB\")\n    \n    if successful:\n        print(\"\\n📁 Generated datasets:\")\n        for result in successful:\n            print(f\"   • {result['name']} - {result['records']:,} records ({result['type']})\")\n    \n    if failed:\n        print(\"\\n❌ Failed datasets:\")\n        for result in failed:\n            print(f\"   • {result['name']} - {result['error']}\")\n    \n    print(\"\\n🎉 Raw data generation completed!\")\n    print(\"📁 All datasets saved in data/raw/ subdirectories\")\n    print(\"=\"*80)\n    \n    return results\n\nif __name__ == \"__main__\":\n    main()\n"